{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "</s>### Human: 回答集编程和Prolog有什么联系和区别？### Assistant: 回答集编程（Answer Set Programming，ASP）和Prolog是两种逻辑编程语言，它们之间的联系和区别如下：\n",
      "\n",
      "联系：\n",
      "1. ASP和Prolog都使用规则和查询来表示和解决问题。\n",
      "2. ASP和Prolog都支持递归和模式匹配。\n",
      "3. ASP和Prolog都可以被用来表示和解决复杂的逻辑和知识表达式。\n",
      "\n",
      "区别：\n",
      "1. ASP的语法更接近于一种自然语言，而Prolog的语法更接近于一种函数式编程语言。\n",
      "2. ASP和Prolog的语义不同。ASP使用基于稳定模型（stable model）的语义来定义规则的解释，而Prolog使用基于霍恩子句（Horn clause）的语义来定义规则的解释。\n",
      "3. ASP和Prolog的应用领域不同。ASP通常用于复杂知识的表示和解决，如自然语言处理、图形学等领域，而Prolog通常用于人工智能、专家系统等领域。### Human: 看来prolog也是挺强大的。为什么它现在不火呢？请试着给出几个原因。### Assistant: Prolog在当今编程语言市场上的影响力不如一些其他语言，可能是由于以下几个原因：\n",
      "\n",
      "1. **学习曲线较陡峭**\n",
      "Prolog语法和概念与传统的命令式编程语言非常不同，这使得初学者在学习过程中可能会遇到一些挑战。在传统的命令式编程语言中，程序员需要考虑如何控制程序的流程以及如何处理数据。而在Prolog中，程序员需要思考如何描述问题和约束条\n",
      "**************************************************\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackyu/Developer/multilingual-alpaca-qlora/.venv/lib/python3.11/site-packages/trl/trainer/utils.py:160: UserWarning: Could not find response key `\n",
      "\n",
      "### Response:\n",
      "` in the following instance: </s>### Human: 回答集编程和Prolog有什么联系和区别？### Assistant: 回答集编程（Answer Set Programming，ASP）和Prolog是两种逻辑编程语言，它们之间的联系和区别如下：\n",
      "\n",
      "联系：\n",
      "1. ASP和Prolog都使用规则和查询来表示和解决问题。\n",
      "2. ASP和Prolog都支持递归和模式匹配。\n",
      "3. ASP和Prolog都可以被用来表示和解决复杂的逻辑和知识表达式。\n",
      "\n",
      "区别：\n",
      "1. ASP的语法更接近于一种自然语言，而Prolog的语法更接近于一种函数式编程语言。\n",
      "2. ASP和Prolog的语义不同。ASP使用基于稳定模型（stable model）的语义来定义规则的解释，而Prolog使用基于霍恩子句（Horn clause）的语义来定义规则的解释。\n",
      "3. ASP和Prolog的应用领域不同。ASP通常用于复杂知识的表示和解决，如自然语言处理、图形学等领域，而Prolog通常用于人工智能、专家系统等领域。### Human: 看来prolog也是挺强大的。为什么它现在不火呢？请试着给出几个原因。### Assistant: Prolog在当今编程语言市场上的影响力不如一些其他语言，可能是由于以下几个原因：\n",
      "\n",
      "1. **学习曲线较陡峭**\n",
      "Prolog语法和概念与传统的命令式编程语言非常不同，这使得初学者在学习过程中可能会遇到一些挑战。在传统的命令式编程语言中，程序员需要考虑如何控制程序的流程以及如何处理数据。而在Prolog中，程序员需要思考如何描述问题和约束条 This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.\n",
      "  warnings.warn(\n",
      "/Users/jackyu/Developer/multilingual-alpaca-qlora/.venv/lib/python3.11/site-packages/trl/trainer/utils.py:160: UserWarning: Could not find response key `\n",
      "\n",
      "### Response:\n",
      "` in the following instance: </s>### Human: Based on our current understanding of physics, biology and chemistry, what is the chance of alien life being within a distance of earth that can be traveled within a human life time at speeds lower than the speed of light?### Assistant: This is a question that is difficult to answer with any certainty. There are many unknown variables that would need to be considered in order to estimate the likelihood of alien life within a distance that can be traveled within a human lifetime at speeds lower than the speed of light.\n",
      "\n",
      "First, we would need to consider the number of potentially habitable planets in the universe. While we have discovered many exoplanets in recent years, we are still unable to determine whether or not they are capable of supporting life. Additionally, we do not yet know how many potentially habitable planets exist beyond our current observational capabilities.\n",
      "\n",
      "Second, we would need to consider the probability of life arising on a given planet. While we have a general understanding of the chemical and environmental conditions that are necessary for life as we know it to exist, we do not know how common these conditions are in the universe.\n",
      "\n",
      "Third, we would need to consider the likelihood of intelligent life developing on a given planet. Even if life does exist elsewhere in the universe, it is unclear how often it evolves to a point of intelligence.\n",
      "\n",
      "Finally, we would need to consider the technological capabilities of any potential alien civilizations. While we can currently travel at speeds slower than the speed of light, we do not know whether or not any potential alien civilizations have developed technology that would allow them to travel at much faster speeds.\n",
      "\n",
      "Given these many unknown variables, it is difficult to estimate the likelihood of alien life being within a distance that can be traveled within a human lifetime at speeds lower than the speed of light. While it is certainly possible that such life exists, we simply do not have enough information to make an accurate prediction.### Human: Aaaa too much text.. summarize your reply in bullet points<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad> This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.\n",
      "  warnings.warn(\n",
      "/Users/jackyu/Developer/multilingual-alpaca-qlora/.venv/lib/python3.11/site-packages/trl/trainer/utils.py:160: UserWarning: Could not find response key `\n",
      "\n",
      "### Response:\n",
      "` in the following instance: </s>### Human: quero que você me ajude a editar uma foto no photoshop. trata-se de uma foto em que uma pessoa está segurando um cabo de vassoura. quero transformar esse cabo de vassoura em um sabre de luz. por favor, seja detalhado em suas instruções pois não estou familiarizado com o software.### Assistant: Claro! Aqui estão as instruções detalhadas sobre como transformar o cabo de vassoura em um sabre de luz no Photoshop:\n",
      "\n",
      "    1 - Abra sua imagem no Photoshop.\n",
      "    2 - Crie uma nova camada clicando em \"Camada\" no menu superior e depois em \"Nova Camada\".\n",
      "    3 - Selecione a ferramenta \"Retângulo de Seleção\" no painel de ferramentas à esquerda.\n",
      "    4 - Desenhe uma seleção ao redor do cabo de vassoura na nova camada.\n",
      "    5 - Pressione \"Ctrl + C\" para copiar a seleção.\n",
      "    6 - Crie uma nova camada pressionando \"Ctrl + Shift + N\".\n",
      "    7 - Pressione \"Ctrl + V\" para colar a seleção na nova camada.\n",
      "    8 - Altere a cor da seleção pressionando \"Ctrl + U\" e escolhendo a cor desejada para o sabre de luz.\n",
      "    9 - Vá até o menu \"Filtro\" no topo e escolha \"Brilho e Contraste\".\n",
      "    10 - Aumente o brilho e o contraste para dar mais vida à imagem do sabre de luz.\n",
      "    11 - Finalmente, use a ferramenta \"Pincel\" para apagar as partes da imagem que não são desejadas, como a parte da mão da pessoa que segura o cabo de vassoura.\n",
      "\n",
      "Siga essas etapas e você terá uma imagem com um sabre de luz em pouco tempo!<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad> This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.\n",
      "  warnings.warn(\n",
      "/Users/jackyu/Developer/multilingual-alpaca-qlora/.venv/lib/python3.11/site-packages/trl/trainer/utils.py:160: UserWarning: Could not find response key `\n",
      "\n",
      "### Response:\n",
      "` in the following instance: </s>### Human: Ich möchte heute um 13Uhr spazieren gehen. Benötige ich dazu einen Regenschirm?### Assistant: Leider bin ich nicht in der Lage den aktuellen Wetterbericht abzurufen um diese Vorhersage akkurat machen zu können.\n",
      "\n",
      "Im Internet, Apps oder im Radio können sie sich über die Wetterbedingungen der nahen Zukunft informieren.### Human: Wie entsteht eigentlich Regen? Kannst Du mir das erklären?### Assistant: Regen entsteht durch den Kreislauf von Wasser in der Atmosphäre, auch als Wasserkreislauf bekannt. Im Wesentlichen verdunstet Wasser aus Oberflächengewässern wie Meeren, Flüssen und Seen sowie aus Boden und Pflanzen und steigt in die Atmosphäre auf.\n",
      "\n",
      "Sobald das aufsteigende Wasser die kalte Luftschicht in der Atmosphäre erreicht, kondensiert es und bildet Wolken. In diesen Wolken sammelt sich weiterhin Feuchtigkeit und es kommt zu einer Kondensation von Wasserdampf auf winzigen Partikeln in der Luft, wie Staub, Salz oder Pollen.\n",
      "\n",
      "Sobald diese Partikel genug Wasser angesammelt haben, wachsen sie und schließen sich zu größeren Tropfen zusammen, die als Regentropfen bezeichnet werden. Diese Regentropfen fallen schließlich aus der Wolke auf die Erdoberfläche, entweder als leichter Nieselregen oder als stärkerer Regen.\n",
      "\n",
      "Die Menge und Intensität des Regens hängt von verschiedenen Faktoren ab, wie der Temperatur, Luftfeuchtigkeit und dem Druck in der Atmosphäre. Auch kann die Art der Wolken, die den Regen produzieren, variieren - zum Beispiel kann es sich um stratus Wolken handeln, die häufig einen leichteren Nieselregen produzieren, oder um cumulonimbus Wolken, die zu stärkeren Gewitterregen führen können.\n",
      "\n",
      "Ich hoffe, das hilft Ihnen weiter!<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad> This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.\n",
      "  warnings.warn(\n",
      "/Users/jackyu/Developer/multilingual-alpaca-qlora/.venv/lib/python3.11/site-packages/trl/trainer/utils.py:160: UserWarning: Could not find response key `\n",
      "\n",
      "### Response:\n",
      "` in the following instance: </s>### Human: Que musica me recomiendas para ir al gimnasio?### Assistant: Según el doctor Dr. Costas Karageorghis explica que las canciones rápidas y fuertes son particularmente estimulantes, por lo que llenan la mayoría de las listas de reproducciones de las personas que se ejercitan en el gimnasio o haciendo crossfit, mientras que géneros como el soft rock o el pop resultan ideal para los corredores. \n",
      "\n",
      "Spotify elaboro una lista en 2018 con estas 10 canciones como las mas usadas para motivarse en el gimnasio\n",
      "\n",
      "1. House Party. The Knocks, Captain Cuts\n",
      "2. OK – Ofenbach Remix. Robin Schulz, James Blunt, Ofenbach\n",
      "3. Drunk Groove. MARUV, Boosin\n",
      "4. Would You Ever. Skrillex, Poo Bear\n",
      "5. If I’m Lucky. Jason Derulo\n",
      "6. 2U (feat. Justin Beaber). David Guetta\n",
      "7. Hola (feat. Maluma). Flo Rida\n",
      "8. New Rules. Dua Lipa\n",
      "9. Downtown. Anitta, J Balvin\n",
      "10. Tell Me You Love Me. Galantis,Throttle<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad> This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.\n",
      "  warnings.warn(\n",
      "/Users/jackyu/Developer/multilingual-alpaca-qlora/.venv/lib/python3.11/site-packages/trl/trainer/utils.py:160: UserWarning: Could not find response key `\n",
      "\n",
      "### Response:\n",
      "` in the following instance: </s>### Human: Estoy programando en JavaScript, tengo el siguiente arreglo: const numbers = [1, 2, 3, 4, 5]; ¿Cómo puedo recorrerlo y multiplicar por 2 cada elemento? No quiero usar un ciclo FOR para esta tarea. El arreglo resultante se debe llamar numbersByTwo.### Assistant: Para multiplicar cada elemento de un array por 2 sin usar el ciclo `for` puedes optar por el uso del método `.map()`.\n",
      "``` javascript\n",
      "const numbers = [1, 2, 3, 4, 5];\n",
      "\n",
      "// multiplica cada elemento del array 'numbers' por 2\n",
      "numbersByTwo = numbers.map(n => n * 2);\n",
      "```<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad> This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.\n",
      "  warnings.warn(\n",
      "/Users/jackyu/Developer/multilingual-alpaca-qlora/.venv/lib/python3.11/site-packages/trl/trainer/utils.py:160: UserWarning: Could not find response key `\n",
      "\n",
      "### Response:\n",
      "` in the following instance: </s>### Human: Qual é a distância da Terra até a Lua### Assistant: A distância média da Terra até a Lua é de 382.500 quilômetros. A distância varia porque a Lua viaja ao redor da Terra em uma órbita elíptica. No perigeu, ponto em que a lua está mais próxima da Terra, a distância é de aproximadamente 360.000 quilômetros.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad> This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.\n",
      "  warnings.warn(\n",
      "/Users/jackyu/Developer/multilingual-alpaca-qlora/.venv/lib/python3.11/site-packages/trl/trainer/utils.py:160: UserWarning: Could not find response key `\n",
      "\n",
      "### Response:\n",
      "` in the following instance: </s>### Human: Explain Simon Sinek's \"Golden Circle\" as if I were six years old. Please provide examples to each of the main parts.### Assistant: The \"Golden Circle\" is a technique of understanding how things work. Imagine a large yellow circle, similar to a hula hoop, with three parts: Why, How, and What.\n",
      "\n",
      "\"Why\" is the most important question. This is the reason you do anything, such as attend to school. Perhaps you attend school to learn and get smarter so that you can grow up and do the things you want to do.\n",
      "\n",
      "\n",
      "The second part is \"how\". It's about how you go about things, such as how you make friends at school. Perhaps you create friends by being helpful and sharing your toys, or by playing games with them.\n",
      "\n",
      "\"What\" is the final part. It is about what you do, not what you learn in school. Perhaps you will learn about numbers, letters, and animals.\n",
      "\n",
      "As a result, the \"Golden Circle\" teaches us that why we do something is more essential than what we do or how we do it. If we begin with \"Why,\" the \"How\" and \"What\" will follow.\n",
      "\n",
      "For example, suppose you wish to make a sandcastle. Your \"why\" could be that you just want to have fun and play in the sand. Your \"How\" could be to gather and sculpt sand using a shovel and bucket. Your \"What\" is the sandcastle you built.### Human: I'm not sure I understood the difference between the how and what,\n",
      "Is the \"what\" part the \"What i want to do\" or is it \"What is to be done\" or is it something else entirely? This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "\n",
    "dataset = load_dataset(\"timdettmers/openassistant-guanaco\", split=\"train\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
    "\n",
    "response_template = \"\\n\\n### Response:\\n\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template=response_template, tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    args=SFTConfig(output_dir=\"/tmp\", per_device_train_batch_size=4),\n",
    "    train_dataset=dataset,\n",
    "    data_collator=collator,\n",
    ")\n",
    "\n",
    "for batch in trainer.get_train_dataloader():\n",
    "    print(len(batch))\n",
    "    break\n",
    "\n",
    "batch['labels'][batch[\"labels\"] == -100] = 1\n",
    "inputs = tokenizer.batch_decode(batch[\"input_ids\"])\n",
    "targets = tokenizer.batch_decode(batch[\"labels\"])\n",
    "print(len(inputs))\n",
    "print(inputs[0])\n",
    "print(\"*\" * 50)\n",
    "print(targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 9846\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from utils.prompter import Prompter\n",
    "\n",
    "dataset = load_dataset(\"yahma/alpaca-cleaned\", split=\"train\")\n",
    "prompter = Prompter()\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.1-8B\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_and_tokenize_prompt(data_point):\n",
    "    full_prompt = prompter.generate_prompt(\n",
    "        data_point[\"instruction\"],\n",
    "        data_point[\"input\"],\n",
    "        data_point[\"output\"],\n",
    "    )\n",
    "\n",
    "    full_prompt_tokens = tokenizer.encode(full_prompt, return_tensors=\"pt\")\n",
    "    output_tokens = tokenizer.encode(data_point[\"output\"], return_tensors=\"pt\")\n",
    "\n",
    "    response_start_index = full_prompt_tokens.shape[1] - output_tokens.shape[1] \n",
    "\n",
    "    return {\n",
    "        \"text\": full_prompt, \n",
    "        # \"response_start_index\": response_start_index\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(generate_and_tokenize_prompt)\n",
    "dataset = dataset.remove_columns([\"instruction\", \"input\", \"output\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackyu/Developer/multilingual-alpaca-qlora/.venv/lib/python3.11/site-packages/trl/trainer/utils.py:134: UserWarning: The pad_token_id and eos_token_id values of this tokenizer are identical. If you are planning for multi-turn training, it can result in the model continuously generating questions and answers without eos token. To avoid this, set the pad_token_id to a different value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m response_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m### Response:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m collator \u001b[38;5;241m=\u001b[39m DataCollatorForCompletionOnlyLM(instruction_template\u001b[38;5;241m=\u001b[39minstruction_template, response_template\u001b[38;5;241m=\u001b[39mresponse_template, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, mlm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mSFTTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSFTConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/tmp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mget_train_dataloader():\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batch), batch)\n",
      "File \u001b[0;32m~/Developer/multilingual-alpaca-qlora/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m         message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m custom_message\n\u001b[1;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/multilingual-alpaca-qlora/.venv/lib/python3.11/site-packages/transformers/utils/deprecation.py:165\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/multilingual-alpaca-qlora/.venv/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:295\u001b[0m, in \u001b[0;36mSFTTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics, peft_config, dataset_text_field, packing, formatting_func, max_seq_length, infinite, num_of_sequences, chars_per_token, dataset_num_proc, dataset_batch_size, neftune_noise_alpha, model_init_kwargs, dataset_kwargs, eval_packing)\u001b[0m\n\u001b[1;32m    292\u001b[0m             peft_module_casting_to_bf16(model)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m processing_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m     processing_class \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241m.\u001b[39m_name_or_path)\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(processing_class, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpad_token\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m         processing_class\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;241m=\u001b[39m processing_class\u001b[38;5;241m.\u001b[39meos_token\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'config'"
     ]
    }
   ],
   "source": [
    "instruction_template = \"\\n\\n### Instruction:\\n\"\n",
    "response_template = \"\\n\\n### Response:\\n\"\n",
    "collator = DataCollatorForCompletionOnlyLM(instruction_template=instruction_template, response_template=response_template, tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    args=SFTConfig(output_dir=\"/tmp\", per_device_train_batch_size=4),\n",
    "    train_dataset=dataset,\n",
    "    data_collator=collator,\n",
    ")\n",
    "\n",
    "for batch in trainer.get_train_dataloader():\n",
    "    print(len(batch), batch)\n",
    "    break\n",
    "\n",
    "batch['labels'][batch[\"labels\"] == -100] = 1\n",
    "inputs = tokenizer.batch_decode(batch[\"input_ids\"])\n",
    "targets = tokenizer.batch_decode(batch[\"labels\"])\n",
    "print(\"batch_size:\", len(inputs))\n",
    "print(inputs[0])\n",
    "print(\"*\" * 50)\n",
    "print(targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "texts = [\"How are you?\", \"What is the capital of France?\"]\n",
    "\n",
    "# [tokenizer.apply_chat_template([text]) for text in texts]\n",
    "inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "outputs = model(**inputs, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The to the doing I\\xa0’t\\xa0', 'The is the difference of the?\\n Paris']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decode logits to text\n",
    "decoded_outputs = tokenizer.batch_decode(outputs.logits.argmax(2), skip_special_tokens=True)\n",
    "decoded_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForCausalLM(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 512, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 1024)\n",
       "      (project_out): Linear(in_features=1024, out_features=512, bias=False)\n",
       "      (project_in): Linear(in_features=512, out_features=1024, bias=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x OPTDecoderLayer(\n",
       "          (self_attn): OPTSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=50272, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43moutputs\u001b[49m\u001b[38;5;241m.\u001b[39mhidden_states)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"
     ]
    }
   ],
   "source": [
    "len(outputs.hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageContrastiveSFTTrainer(SFTTrainer):\n",
    "    def compute_contrastive_loss(self, outputs):\n",
    "        first_layer_hidden_states = outputs.hidden_states[1]\n",
    "        hidden_states = torch.stack(hidden_states, dim=1)\n",
    "        hidden_states = hidden_states[:, -1]\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        print(\"Computing SFT loss\")\n",
    "        nll_loss, outputs = super().compute_loss(model, inputs, return_outputs=True, num_items_in_batch=num_items_in_batch)\n",
    "        print(\"Computing contrastive loss\")\n",
    "        contrastive_loss = self.compute_contrastive_loss(outputs)\n",
    "        alpha = self.args.alpha\n",
    "        loss = (1 - alpha) * nll_loss + alpha * contrastive_loss\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
